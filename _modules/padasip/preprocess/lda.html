
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>padasip.preprocess.lda &#8212; Padasip 1.2.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="description" content="Padasip - Python Adaptive Signal Processing">
    <meta name="keywords" content="Adaptive,Signal,Processing,Filters,Neural Networks,">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-73796119-2', 'auto');
      ga('send', 'pageview');
    </script>

  </head><body>


  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for padasip.preprocess.lda</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">.. versionadded:: 0.6</span>

<span class="sd">Linear discriminant analysis (LDA)</span>
<span class="sd">is a method used to determine the features</span>
<span class="sd">that separates some classes of items. The output of LDA may be used as</span>
<span class="sd">a linear classifier, or for dimensionality reduction for purposes of</span>
<span class="sd">classification.</span>

<span class="sd">.. contents::</span>
<span class="sd">   :local:</span>
<span class="sd">   :depth: 1</span>

<span class="sd">See also: :ref:`preprocess-pca`</span>

<span class="sd">Usage Explanation</span>
<span class="sd">********************</span>

<span class="sd">For reduction of data-set :code:`x` with labels stored in array (:code:`labels`)</span>
<span class="sd">to new dataset :code:`new_x` containg just :code:`n` number of</span>
<span class="sd">columns</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    new_x = pa.preprocess.LDA(x, labels, n)</span>

<span class="sd">The sorted array of scattermatrix eigenvalues for dataset :code:`x` described</span>
<span class="sd">with variable :code:`labels` can be obtained as follows</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    eigenvalues = pa.preprocess.LDA_discriminants(x, labels)</span>


<span class="sd">Minimal Working Examples</span>
<span class="sd">*****************************</span>

<span class="sd">In this example we create data-set :code:`x` of 150 random samples. Every sample</span>
<span class="sd">is described by 4 values and label. The labels are stored in</span>
<span class="sd">array :code:`labels`.</span>

<span class="sd">Firstly, it is good to see the eigenvalues of scatter matrix to determine</span>
<span class="sd">how many rows is reasonable to reduce</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    import numpy as np</span>
<span class="sd">    import padasip as pa</span>

<span class="sd">    np.random.seed(100) # constant seed to keep the results consistent</span>

<span class="sd">    N = 150 # number of samples</span>
<span class="sd">    classes = np.array([&quot;1&quot;, &quot;a&quot;, 3]) # names of classes</span>
<span class="sd">    cols = 4 # number of features (columns in dataset)</span>

<span class="sd">    x = np.random.random((N, cols)) # random data</span>
<span class="sd">    labels = np.random.choice(classes, size=N) # random labels</span>

<span class="sd">    print pa.preprocess.LDA_discriminants(x, labels)</span>

<span class="sd">what prints</span>

<span class="sd">&gt;&gt;&gt; [  2.90863957e-02   2.28352079e-02   1.23545720e-18  -1.61163011e-18]</span>

<span class="sd">From this output it is obvious that reasonable number of columns to keep is 2.</span>
<span class="sd">The following code reduce the number of features to 2.</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    import numpy as np</span>
<span class="sd">    import padasip as pa</span>

<span class="sd">    np.random.seed(100) # constant seed to keep the results consistent</span>

<span class="sd">    N = 150 # number of samples</span>
<span class="sd">    classes = np.array([&quot;1&quot;, &quot;a&quot;, 3]) # names of classes</span>
<span class="sd">    cols = 4 # number of features (columns in dataset)</span>

<span class="sd">    x = np.random.random((N, cols)) # random data</span>
<span class="sd">    labels = np.random.choice(classes, size=N) # random labels</span>

<span class="sd">    new_x = pa.preprocess.LDA(x, labels, n=2)</span>

<span class="sd">to check if the size of new data-set is really correct we can print the shapes</span>
<span class="sd">as follows</span>

<span class="sd">&gt;&gt;&gt; print &quot;Shape of original dataset: {}&quot;.format(x.shape)</span>
<span class="sd">Shape of original dataset: (150, 4)</span>
<span class="sd">&gt;&gt;&gt; print &quot;Shape of new dataset: {}&quot;.format(new_x.shape)</span>
<span class="sd">Shape of new dataset: (150, 2)</span>


<span class="sd">Code Explanation</span>
<span class="sd">*****************</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<div class="viewcode-block" id="LDA_base"><a class="viewcode-back" href="../../../sources/preprocess/lda.html#padasip.preprocess.lda.LDA_base">[docs]</a><span class="k">def</span> <span class="nf">LDA_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base function used for Linear Discriminant Analysis.</span>

<span class="sd">    **Args:**</span>

<span class="sd">    * `x` : input matrix (2d array), every row represents new sample</span>

<span class="sd">    * `labels` : list of labels (iterable), every item should be label for \</span>
<span class="sd">      sample with corresponding index</span>

<span class="sd">    **Returns:**</span>

<span class="sd">    * `eigenvalues`, `eigenvectors` : eigenvalues and eigenvectors \</span>
<span class="sd">      from LDA analysis</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># mean values for every class</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
        <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># scatter matrices</span>
    <span class="n">scatter_within</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cols</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">cl</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">means</span><span class="p">):</span>
        <span class="n">scatter_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cols</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cl</span><span class="p">]:</span>
            <span class="n">dif</span> <span class="o">=</span> <span class="n">row</span> <span class="o">-</span> <span class="n">mean</span>
            <span class="n">scatter_class</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">scatter_within</span> <span class="o">+=</span> <span class="n">scatter_class</span>
    <span class="n">total_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">scatter_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cols</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">cl</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">means</span><span class="p">):</span>
        <span class="n">dif</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">total_mean</span>
        <span class="n">dif_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">scatter_between</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cl</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dif_product</span>
    <span class="c1"># eigenvalues and eigenvectors from scatter matrices</span>
    <span class="n">scatter_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">scatter_within</span><span class="p">),</span> <span class="n">scatter_between</span><span class="p">)</span>
    <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">scatter_product</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span></div>

<div class="viewcode-block" id="LDA"><a class="viewcode-back" href="../../../sources/preprocess/lda.html#padasip.preprocess.lda.LDA">[docs]</a><span class="k">def</span> <span class="nf">LDA</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear Discriminant Analysis function.</span>

<span class="sd">    **Args:**</span>

<span class="sd">    * `x` : input matrix (2d array), every row represents new sample</span>

<span class="sd">    * `labels` : list of labels (iterable), every item should be label for \</span>
<span class="sd">      sample with corresponding index</span>

<span class="sd">    **Kwargs:**</span>

<span class="sd">    * `n` : number of features returned (integer) - how many columns</span>
<span class="sd">      should the output keep</span>

<span class="sd">    **Returns:**</span>

<span class="sd">    * new_x : matrix with reduced size (number of columns are equal `n`)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="k">if</span> <span class="n">n</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="s2">&quot;The requested n is bigger than </span><span class="se">\</span>
<span class="s2">        number of features in x.&quot;</span>
    <span class="c1"># make the LDA</span>
    <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">LDA_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="c1"># sort the eigen vectors according to eigen values</span>
    <span class="n">eigen_order</span> <span class="o">=</span> <span class="n">eigen_vectors</span><span class="o">.</span><span class="n">T</span><span class="p">[(</span><span class="o">-</span><span class="n">eigen_values</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">eigen_order</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span></div>


<div class="viewcode-block" id="LDA_discriminants"><a class="viewcode-back" href="../../../sources/preprocess/lda.html#padasip.preprocess.lda.LDA_discriminants">[docs]</a><span class="k">def</span> <span class="nf">LDA_discriminants</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear Discriminant Analysis helper for determination how many columns of</span>
<span class="sd">    data should be reduced.</span>

<span class="sd">    **Args:**</span>

<span class="sd">    * `x` : input matrix (2d array), every row represents new sample</span>

<span class="sd">    * `labels` : list of labels (iterable), every item should be label for \</span>
<span class="sd">        sample with corresponding index</span>

<span class="sd">    **Returns:**</span>

<span class="sd">    * `discriminants` : array of eigenvalues sorted in descending order</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># validate inputs</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Impossible to convert x to a numpy array.&#39;</span><span class="p">)</span>
    <span class="c1"># make the LDA</span>
    <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">LDA_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eigen_values</span><span class="p">[(</span><span class="o">-</span><span class="n">eigen_values</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">

<a href="https://github.com/matousc89/padasip"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

<iframe src="https://ghbtns.com/github-btn.html?user=matousc89&repo=padasip&type=watch&count=true&size=large&v=2" frameborder="0" scrolling="0" width="160px" height="30px" style="margin-bottom: 5px;"></iframe>

<iframe src="https://ghbtns.com/github-btn.html?user=matousc89&repo=padasip&type=star&count=true&size=large" frameborder="0" scrolling="0" width="160px" height="30px" style="margin-bottom: 15px;"></iframe>

<h3><a href="../../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Padasip</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../sources/preprocess.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sources/filters.html">Adaptive Filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sources/detection.html">Detection Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sources/misc.html">Miscellaneous</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Matous C.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.4.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>